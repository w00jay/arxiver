{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c040e712-d339-43cb-bdff-03680a5a2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from chromadb.utils import embedding_functions\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1f98c9b-ad5b-43e0-b7ab-4e4a66276d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CUTOFF = 3003  # 2711 2424 2155 1880 1572 1016 817 502 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34115fc5-9f10-4615-8fc6-54f1206885da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_interested_entry(database_path):\n",
    "    # Create a database connection\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SQL query to find the last occurrence of \"interested\" = 1\n",
    "    query = \"\"\"\n",
    "    SELECT paper_id FROM papers \n",
    "    WHERE interested = 1 \n",
    "    ORDER BY paper_id ASC \n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        last_interested = cursor.fetchone()\n",
    "        if last_interested:\n",
    "            print(\"Last interested entry:\", last_interested)\n",
    "            return {\"paper_id\": last_interested[0]}\n",
    "        else:\n",
    "            print(\"No interested entries found.\")\n",
    "            return nil\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Database error:\", e)\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe783ae0-0c05-4ec7-8e9b-33d972deab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last interested entry: ('http://arxiv.org/abs/1706.03762v7',)\n",
      "{\n",
      "    \"paper_id\": \"http://arxiv.org/abs/1706.03762v7\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "db = \"../data/arxiv_papers.db\"\n",
    "last_interested = find_last_interested_entry(db)\n",
    "print(json.dumps(last_interested, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca3218c5-a977-4691-b11f-760b7e620bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(database_path):\n",
    "    # Create a database connection\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.row_factory = sqlite3.Row\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT paper_id, concise_summary, interested FROM papers \n",
    "    ORDER BY paper_id ASC \n",
    "    LIMIT {TRAIN_CUTOFF};\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        articles = cursor.fetchall()\n",
    "        if articles:\n",
    "            print(f\"Got {len(articles)}.\")\n",
    "            return articles\n",
    "        else:\n",
    "            print(\"No interested entries found.\")\n",
    "            return nil\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Database error:\", e)\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "115b2d07-576a-4260-9165-4d2772b009f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(paper_id, vdb_path=\"../data/arxiv_embeddings.chroma\"):\n",
    "    vdb = chromadb.PersistentClient(vdb_path)\n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=\"all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    embedding_func = sentence_transformer_ef\n",
    "    vectors = vdb.get_or_create_collection(\n",
    "        name=\"arxiver\", embedding_function=embedding_func\n",
    "    )\n",
    "\n",
    "    res = vectors.get(ids=[paper_id], limit=1, include=[\"embeddings\"])\n",
    "    # print(res)\n",
    "    # print(res[\"embeddings\"][0])\n",
    "    # print(f'{res[\"ids\"][0]} {res[\"embeddings\"][0]}')\n",
    "    return res[\"embeddings\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc22c976-1746-4844-8dfd-d194e6c26da2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0028905950020998716,\n",
       " -0.05982412025332451,\n",
       " -0.008419168181717396,\n",
       " -0.01921667717397213,\n",
       " 0.014117264188826084,\n",
       " 0.031683020293712616,\n",
       " -0.04353299364447594,\n",
       " 0.07392609864473343,\n",
       " 0.07040511816740036,\n",
       " -0.05495050922036171,\n",
       " -0.011163090355694294,\n",
       " -0.010397370904684067,\n",
       " 0.04608140140771866,\n",
       " 0.009848348796367645,\n",
       " -0.010315321385860443,\n",
       " 0.013171806000173092,\n",
       " 0.0007975147454999387,\n",
       " 0.023529132828116417,\n",
       " -0.08075197786092758,\n",
       " -0.06419838964939117,\n",
       " 0.040608182549476624,\n",
       " 0.04551651328802109,\n",
       " 0.03515498712658882,\n",
       " -0.011132987216114998,\n",
       " 0.03609246760606766,\n",
       " 0.014492835849523544,\n",
       " -0.04349182918667793,\n",
       " -0.07201968133449554,\n",
       " -0.03566231578588486,\n",
       " -0.0035466880071908236,\n",
       " -0.0017921729013323784,\n",
       " -1.6525307728443295e-05,\n",
       " -0.003994284197688103,\n",
       " 0.11520082503557205,\n",
       " -0.042225077748298645,\n",
       " 0.021955693140625954,\n",
       " -0.0885772779583931,\n",
       " 0.0006367009482346475,\n",
       " -0.0018035508692264557,\n",
       " -0.04127293825149536,\n",
       " -0.03715188056230545,\n",
       " -0.04181300103664398,\n",
       " 0.004717599134892225,\n",
       " 0.020079748705029488,\n",
       " 0.12638629972934723,\n",
       " 0.011757900007069111,\n",
       " 0.013007208704948425,\n",
       " 0.011290333233773708,\n",
       " 0.04141438007354736,\n",
       " 0.014196956530213356,\n",
       " -0.09675116091966629,\n",
       " -0.042060814797878265,\n",
       " 0.012644651345908642,\n",
       " 0.057601045817136765,\n",
       " -0.014588892459869385,\n",
       " 0.05498352274298668,\n",
       " 0.006518681533634663,\n",
       " 0.03475780412554741,\n",
       " -0.004166896920651197,\n",
       " -0.0547633096575737,\n",
       " -0.06210476905107498,\n",
       " -0.018257195129990578,\n",
       " -0.027639886364340782,\n",
       " -0.012833566404879093,\n",
       " 0.03485867753624916,\n",
       " -0.012836847454309464,\n",
       " 0.01864645443856716,\n",
       " -0.01383234467357397,\n",
       " -0.10308153927326202,\n",
       " -0.013363003730773926,\n",
       " -0.008456509560346603,\n",
       " 0.05769491568207741,\n",
       " 0.014770819805562496,\n",
       " 0.08211624622344971,\n",
       " 0.0766645297408104,\n",
       " 0.025611035525798798,\n",
       " 0.010705484077334404,\n",
       " 0.02064969204366207,\n",
       " 0.04949244111776352,\n",
       " -0.02814926952123642,\n",
       " 0.023817570880055428,\n",
       " -0.01734309270977974,\n",
       " 0.10586445778608322,\n",
       " 0.032064151018857956,\n",
       " 0.09077880531549454,\n",
       " -0.058521151542663574,\n",
       " 0.04660880193114281,\n",
       " 0.03993644937872887,\n",
       " -0.04132290929555893,\n",
       " -0.00570293515920639,\n",
       " -0.05313454195857048,\n",
       " -0.09578235447406769,\n",
       " 0.10896845161914825,\n",
       " 0.030625859275460243,\n",
       " -0.0386124849319458,\n",
       " 0.039430346339941025,\n",
       " -0.02810133621096611,\n",
       " -0.033900488168001175,\n",
       " -0.05214226245880127,\n",
       " 0.028485054150223732,\n",
       " -0.03289109468460083,\n",
       " 0.03164559602737427,\n",
       " 0.04005889967083931,\n",
       " -0.04602324217557907,\n",
       " -0.07989565283060074,\n",
       " -0.0009359910618513823,\n",
       " 0.07038108259439468,\n",
       " 0.030079830437898636,\n",
       " 0.06147569790482521,\n",
       " -0.10333587229251862,\n",
       " 0.04233980178833008,\n",
       " 0.007875493727624416,\n",
       " -0.01761510968208313,\n",
       " -0.07361552119255066,\n",
       " 0.06073106825351715,\n",
       " -0.08448058366775513,\n",
       " -0.0004528039426077157,\n",
       " -0.04509928822517395,\n",
       " 0.022964410483837128,\n",
       " 0.02608148567378521,\n",
       " -0.059468913823366165,\n",
       " 0.060292020440101624,\n",
       " -0.037970785051584244,\n",
       " 0.009102054871618748,\n",
       " 0.006651001982390881,\n",
       " -0.00798786710947752,\n",
       " 0.011957261711359024,\n",
       " 2.5165236528372927e-33,\n",
       " 0.02581857517361641,\n",
       " 0.0823797732591629,\n",
       " 0.0284844059497118,\n",
       " -0.007864858023822308,\n",
       " -0.0011038660304620862,\n",
       " -0.02199939824640751,\n",
       " -0.026142528280615807,\n",
       " 0.05926758423447609,\n",
       " -0.062602199614048,\n",
       " -0.07133104652166367,\n",
       " -0.04836658015847206,\n",
       " -0.03397873044013977,\n",
       " -0.014098023995757103,\n",
       " 0.05687042698264122,\n",
       " -0.046055782586336136,\n",
       " -0.0670304074883461,\n",
       " 0.03613744303584099,\n",
       " 0.06256747990846634,\n",
       " -0.003219716949388385,\n",
       " 0.007038390263915062,\n",
       " -0.001788127003237605,\n",
       " 0.0024882876314222813,\n",
       " 0.07505842298269272,\n",
       " -0.018026553094387054,\n",
       " 0.038580309599637985,\n",
       " -0.01872418448328972,\n",
       " 0.07932816445827484,\n",
       " -0.08097332715988159,\n",
       " -0.03731519728899002,\n",
       " -0.040234215557575226,\n",
       " -0.11377225816249847,\n",
       " -0.010386548936367035,\n",
       " -0.0024661184288561344,\n",
       " -0.01689758524298668,\n",
       " -0.006094949785619974,\n",
       " -0.09949196875095367,\n",
       " 0.007345006801187992,\n",
       " -0.021560614928603172,\n",
       " 0.035761334002017975,\n",
       " -0.060414332896471024,\n",
       " 0.0069123525172472,\n",
       " 0.04494389519095421,\n",
       " -0.013454418629407883,\n",
       " 0.06919834762811661,\n",
       " -0.04331161826848984,\n",
       " 0.004497344605624676,\n",
       " -0.035546641796827316,\n",
       " 0.02130165882408619,\n",
       " 0.038706567138433456,\n",
       " 0.002912509487941861,\n",
       " 0.021952755749225616,\n",
       " -0.012775328941643238,\n",
       " -0.0706549808382988,\n",
       " -0.0008192004170268774,\n",
       " 0.14082065224647522,\n",
       " 0.10919435322284698,\n",
       " 0.08978234976530075,\n",
       " 0.06376867741346359,\n",
       " 0.029147319495677948,\n",
       " -0.014399693347513676,\n",
       " 0.06926445662975311,\n",
       " 0.022194435819983482,\n",
       " 0.029614677652716637,\n",
       " 0.10733402520418167,\n",
       " 0.08786888420581818,\n",
       " -0.013682455755770206,\n",
       " -0.02477351203560829,\n",
       " 0.043912407010793686,\n",
       " 0.026661992073059082,\n",
       " -0.01982146129012108,\n",
       " -0.10243168473243713,\n",
       " -0.04090846702456474,\n",
       " 0.019132958725094795,\n",
       " -0.01799425482749939,\n",
       " 0.032766666263341904,\n",
       " 0.039304908365011215,\n",
       " -0.03843339905142784,\n",
       " -0.09827830642461777,\n",
       " 0.023127039894461632,\n",
       " -0.017350582405924797,\n",
       " -0.05373495817184448,\n",
       " -0.05983688682317734,\n",
       " 0.020376145839691162,\n",
       " -0.02197766676545143,\n",
       " -0.014613676816225052,\n",
       " 0.034862954169511795,\n",
       " 0.08134778589010239,\n",
       " -0.04964283108711243,\n",
       " 0.03425081446766853,\n",
       " 0.05430987849831581,\n",
       " 0.007954113185405731,\n",
       " 0.0023705866187810898,\n",
       " -0.10456972569227219,\n",
       " 0.022812355309724808,\n",
       " 0.017031779512763023,\n",
       " -4.796296131263253e-34,\n",
       " -0.05020258203148842,\n",
       " 0.013796033337712288,\n",
       " -0.11083831638097763,\n",
       " 0.07449213415384293,\n",
       " -0.015627939254045486,\n",
       " -0.05493006110191345,\n",
       " 0.0074884421192109585,\n",
       " -1.392148533341242e-05,\n",
       " -0.01828034780919552,\n",
       " 0.02225387468934059,\n",
       " 0.003474305383861065,\n",
       " -0.08403202146291733,\n",
       " 0.05502568185329437,\n",
       " -0.029674895107746124,\n",
       " 0.024385983124375343,\n",
       " -0.025049323216080666,\n",
       " 0.03823332116007805,\n",
       " 0.033692535012960434,\n",
       " -0.021262360736727715,\n",
       " 0.03806140646338463,\n",
       " -0.0458279512822628,\n",
       " 0.1076563224196434,\n",
       " -0.03481616824865341,\n",
       " 0.013495235703885555,\n",
       " -0.0657079890370369,\n",
       " -0.024796826764941216,\n",
       " -0.08048851042985916,\n",
       " 0.09278421849012375,\n",
       " -0.005915334448218346,\n",
       " -0.025416476652026176,\n",
       " -0.02760729379951954,\n",
       " -0.01883764937520027,\n",
       " -0.0013625622959807515,\n",
       " -0.006969819776713848,\n",
       " -0.0352175235748291,\n",
       " 0.09222719818353653,\n",
       " -0.015587574802339077,\n",
       " -0.025410177186131477,\n",
       " -0.0013889383990317583,\n",
       " 0.08626660704612732,\n",
       " 0.0302477665245533,\n",
       " -0.03115040250122547,\n",
       " -0.07790698856115341,\n",
       " 0.012668192386627197,\n",
       " -0.03032251074910164,\n",
       " 0.010595801286399364,\n",
       " -0.06629183143377304,\n",
       " -0.05759246647357941,\n",
       " -0.0806887075304985,\n",
       " 0.06706751883029938,\n",
       " -0.016519663855433464,\n",
       " 0.05443289130926132,\n",
       " -0.09512640535831451,\n",
       " -0.005788971204310656,\n",
       " 0.01710953563451767,\n",
       " -0.06744519621133804,\n",
       " 0.002820655470713973,\n",
       " -0.11469588428735733,\n",
       " 0.023759180679917336,\n",
       " -0.07132615149021149,\n",
       " -0.01152228657156229,\n",
       " 0.00253187189809978,\n",
       " 0.09542519599199295,\n",
       " -0.05729883536696434,\n",
       " 0.029876528307795525,\n",
       " -0.03361739218235016,\n",
       " 0.016422713175415993,\n",
       " 0.02572963573038578,\n",
       " 0.07007206231355667,\n",
       " 0.026846079155802727,\n",
       " 0.08938849717378616,\n",
       " -0.044983871281147,\n",
       " 0.04989135265350342,\n",
       " 0.09656819701194763,\n",
       " 0.0025089753326028585,\n",
       " -0.0503481887280941,\n",
       " 0.05605089291930199,\n",
       " -0.03094080276787281,\n",
       " -0.012704077176749706,\n",
       " -0.08784835040569305,\n",
       " -0.058938492089509964,\n",
       " 0.024570347741246223,\n",
       " 0.004714910872280598,\n",
       " -0.006849863566458225,\n",
       " 0.04557708650827408,\n",
       " 0.03507419303059578,\n",
       " 0.11560025811195374,\n",
       " 0.01753433234989643,\n",
       " 0.08356227725744247,\n",
       " 0.04243360459804535,\n",
       " 0.030097542330622673,\n",
       " 0.07830106467008591,\n",
       " 0.0019216955406591296,\n",
       " 0.047605715692043304,\n",
       " -0.057128746062517166,\n",
       " -3.832630568467721e-08,\n",
       " -0.13467082381248474,\n",
       " 0.05680611729621887,\n",
       " -0.07750553637742996,\n",
       " 0.057495612651109695,\n",
       " 0.0014966120943427086,\n",
       " -0.1353536993265152,\n",
       " -0.038904037326574326,\n",
       " 0.07061344385147095,\n",
       " 0.007386479992419481,\n",
       " 0.0027843602001667023,\n",
       " -0.004012160934507847,\n",
       " -0.06161164864897728,\n",
       " -0.062478601932525635,\n",
       " -0.06454472988843918,\n",
       " 0.058466773480176926,\n",
       " 0.06014438346028328,\n",
       " 0.07677017152309418,\n",
       " 0.04895259067416191,\n",
       " 0.01756599172949791,\n",
       " 0.02159186638891697,\n",
       " 0.020403876900672913,\n",
       " 0.051930561661720276,\n",
       " 0.0025324206799268723,\n",
       " 0.003166384994983673,\n",
       " 0.02638803794980049,\n",
       " -0.02905111014842987,\n",
       " -0.05093410238623619,\n",
       " -0.030604036524891853,\n",
       " 0.02279680036008358,\n",
       " -0.07476367801427841,\n",
       " 0.033352117985486984,\n",
       " 0.030942166224122047,\n",
       " 0.009441320784389973,\n",
       " -0.03638001158833504,\n",
       " 0.04586214944720268,\n",
       " 0.10565483570098877,\n",
       " 0.05580025911331177,\n",
       " 0.05097644031047821,\n",
       " 0.04594162106513977,\n",
       " 0.06616783887147903,\n",
       " 0.07614389061927795,\n",
       " -0.013218332082033157,\n",
       " -0.08438953012228012,\n",
       " 0.055680517107248306,\n",
       " -0.05342602729797363,\n",
       " -0.047794412821531296,\n",
       " -0.06236325576901436,\n",
       " -0.0622422955930233,\n",
       " 0.05747947841882706,\n",
       " -0.09390784800052643,\n",
       " 0.11438514292240143,\n",
       " -0.03989621251821518,\n",
       " -0.02858893945813179,\n",
       " 0.011010554619133472,\n",
       " 0.009946401230990887,\n",
       " 0.025340154767036438,\n",
       " 0.049351975321769714,\n",
       " -0.05128622427582741,\n",
       " 0.08521975576877594,\n",
       " 0.050311338156461716,\n",
       " 0.022854430601000786,\n",
       " 0.060489870607852936,\n",
       " -0.060847047716379166,\n",
       " -0.04929362237453461]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding(articles[0][\"paper_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3abb7b26-c040-411e-800c-80254d8680c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3003.\n",
      "(3003, 384) (3003,)\n"
     ]
    }
   ],
   "source": [
    "articles = get_data(db)\n",
    "X_article = []\n",
    "y_article = []\n",
    "for article in articles:\n",
    "    # print(\n",
    "    #     f'{article[\"paper_id\"]}, {article[\"interested\"]}\\n{article[\"concise_summary\"]}'\n",
    "    # )\n",
    "    embedding = get_embedding(article[\"paper_id\"])\n",
    "    interested = article[\"interested\"]\n",
    "\n",
    "    if np.any(np.isnan(embedding)):\n",
    "        print(f'{article[\"paper_id\"]} embedding is NaN: {embedding}')\n",
    "    if len(embedding) == 0:\n",
    "        print(f'{article[\"paper_id\"]} embedding is empty')\n",
    "    # if interested.dtype == \"object\":\n",
    "    #     print(f'{article[\"paper_id\"]} embedding is object: {interested}')\n",
    "    X_article.append(embedding)\n",
    "    y_article.append(interested)\n",
    "\n",
    "# print(X_article[:3])\n",
    "# print(y_article[:3])\n",
    "\n",
    "X = np.array(X_article)\n",
    "y = np.array(y_article)\n",
    "\n",
    "# print(X[:1])\n",
    "# print(y[:1])\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "05805479-ad97-46da-907d-90957faac493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 1\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]), y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e62a7967-49b5-48ee-9f5e-4b03a83bf28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2402, 384) (2402,) (601, 384) (601,)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# # Convert data types\n",
    "\n",
    "if y_train.dtype == object:\n",
    "    y_train = y_train.astype(float)\n",
    "\n",
    "# X_train = X_train.astype('float32')\n",
    "# y_train = y_train.astype('int32')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "069c1ea5-bd39-46d8-8229-759cd8e84385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train: float64\n",
      "Data type of y_train: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type of X_train:\", X_train.dtype)\n",
    "print(\"Data type of y_train:\", y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5f5deac1-cfc3-43f0-9aad-bcb0c71a3150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in X_train: False\n",
      "NaN in y_train: False\n",
      "Infinite in X_train: True\n",
      "Infinite in y_train: True\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN in X_train:\", np.any(np.isnan(X_train)))\n",
    "print(\"NaN in y_train:\", np.any(np.isnan(y_train)))\n",
    "print(\"Infinite in X_train:\", np.all(np.isfinite(X_train)))\n",
    "print(\"Infinite in y_train:\", np.all(np.isfinite(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4624ccb4-0a03-48fc-b910-557dfb5d9c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = Sequential(\n",
    "    # [\n",
    "    #     Dense(384, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "    #     Dropout(0.2),\n",
    "    #     Dense(64, activation=\"relu\"),\n",
    "    #     Dense(1, activation=\"sigmoid\"),\n",
    "    # ]\n",
    "    [\n",
    "        Dense(384, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "        Dense(224, activation=\"relu\"),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "532f9ae5-0a9e-429b-a1f8-d442f3582efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.2325 - accuracy: 0.9459 - val_loss: 0.1841 - val_accuracy: 0.9501\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9474 - val_loss: 0.1766 - val_accuracy: 0.9501\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9474 - val_loss: 0.1819 - val_accuracy: 0.9501\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9474 - val_loss: 0.1957 - val_accuracy: 0.9501\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9552 - val_loss: 0.2037 - val_accuracy: 0.9439\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9745 - val_loss: 0.2466 - val_accuracy: 0.9356\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9927 - val_loss: 0.2959 - val_accuracy: 0.9272\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.3217 - val_accuracy: 0.9272\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.3468 - val_accuracy: 0.9335\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.3872 - val_accuracy: 0.8981\n",
      "Epoch 11/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.3989 - val_accuracy: 0.9252\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.4152 - val_accuracy: 0.9314\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.4375 - val_accuracy: 0.9210\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.4461 - val_accuracy: 0.9293\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.4591 - val_accuracy: 0.9314\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.4852 - val_accuracy: 0.9314\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.5016 - val_accuracy: 0.9356\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.4987 - val_accuracy: 0.9252\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.4993 - val_accuracy: 0.9210\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.9314\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 4.8154e-04 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.9252\n",
      "Epoch 22/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 4.0972e-04 - accuracy: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.9252\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 3.4637e-04 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.9252\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 3.2660e-04 - accuracy: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.9231\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.6435e-04 - accuracy: 1.0000 - val_loss: 0.5712 - val_accuracy: 0.9252\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.3428e-04 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.9252\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 1.6228e-04 - accuracy: 1.0000 - val_loss: 0.5862 - val_accuracy: 0.9252\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 1.5570e-04 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.9231\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 1.5238e-04 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.9252\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 1.6797e-04 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4a2f915c90>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "473d8456-003d-48ca-aec8-fa6c8f99bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "import datetime\n",
    "\n",
    "formatted_time = datetime.datetime.now().strftime(f\"%Y%m%d_%H%M\")\n",
    "model.save(f\"model-{formatted_time}-{TRAIN_CUTOFF}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a43cedba-e5ff-413e-b2e1-89c2dfd1e79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       571\n",
      "           1       0.31      0.13      0.19        30\n",
      "\n",
      "    accuracy                           0.94       601\n",
      "   macro avg       0.63      0.56      0.58       601\n",
      "weighted avg       0.92      0.94      0.93       601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "predictions = model.predict(X_test) > 0.5\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53ab900e-d34b-4920-adf1-fb1c32f99f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data(database_path):\n",
    "    # Create a database connection\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.row_factory = sqlite3.Row\n",
    "\n",
    "    # SQL query to find the last occurrence of \"interested\" = 1\n",
    "    query = f\"\"\"\n",
    "    SELECT paper_id, concise_summary FROM papers\n",
    "    ORDER BY paper_id ASC\n",
    "    LIMIT 2000 OFFSET {TRAIN_CUTOFF};\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        articles = cursor.fetchall()\n",
    "        if articles:\n",
    "            print(f\"Got {len(articles)}.\")\n",
    "            return articles\n",
    "        else:\n",
    "            print(\"No interested entries found.\")\n",
    "            return nil\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Database error:\", e)\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f93e5fb3-87a4-40ee-be94-0eda3ae02a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://arxiv.org/abs/2404.04237v1'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ids = get_new_data(db)\n",
    "\n",
    "new_ids[0][\"paper_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b6dbb32a-31dc-44f0-b399-95c974a909f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted articles\n",
    "\n",
    "new_x = []\n",
    "formatted = []\n",
    "for id in new_ids:\n",
    "    new_x.append(get_embedding(id[\"paper_id\"]))\n",
    "\n",
    "new_preds = model.predict(new_x) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0e3d6c35-587d-44d0-953e-809e78bf047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/abs/2404.04298v1: [ True]\n",
      "The study investigates whether Language Models (LLMs) can enhance their performance by refining previous outputs. Despite introducing a framework to evaluate generative and discriminative abilities, the experimental analysis of various LLMs suggests that they do not consistently excel in discrimination over initial generation, which could impact the advancement of self-improving AI systems.\n",
      "http://arxiv.org/abs/2404.04361v1: [ True]\n",
      "The study examines Large Language Models' (LLMs) effectiveness in predicting entity-specific sentiment from political news articles using zero-shot and few-shot strategies. The research highlights LLMs' superior performance over fine-tuned BERT models in capturing entity-specific sentiment, emphasizing the significance of suitable prompting strategies and model architectures in entity-centric sentiment analysis within the political news domain.\n",
      "http://arxiv.org/abs/2404.04540v1: [ True]\n",
      "Foundation models (FMs) have transformed various computing domains such as Automated Planning and Scheduling (APS) by aiding in tasks like plan generation, translation, and optimization. This paper emphasizes the importance of developing a comprehensive FM specifically for planning-like (PL) tasks like business processes and workflows to enhance problem-solving capabilities similar to how large language models (LLMs) are benefiting APS.\n",
      "http://arxiv.org/abs/2404.04570v1: [ True]\n",
      "This text discusses the impact of large language models on AI system interaction patterns and highlights the lack of focus on human interaction with LLM in current literature reviews. The authors conducted a detailed review and mapping of 110 relevant publications, offering insights into human-LLM interaction patterns and identifying key challenges in this area.\n",
      "http://arxiv.org/abs/2404.04750v2: [ True]\n",
      "The advancements in artificial intelligence present both opportunities and challenges for society, with the potential to significantly impact humanity akin to the industrial revolution. The One Hundred Year Study on AI, founded by multidisciplinary experts, emphasizes the importance of understanding AI models, addressing societal impacts, and fostering collaboration among stakeholders to guide the development of AI responsibly for human benefit.\n",
      "http://arxiv.org/abs/2404.04821v1: [ True]\n",
      "AI is reshaping Software Engineering with a focus on Automated Software Evolution for intelligent applications, presenting complexity from data heterogeneity and changing contexts. A proposed conceptual framework emphasizes multimodality learning and offers a Selective Sequential Scope Model (3S) for categorizing research across SE phases, serving as a practical guide for practitioners venturing into this evolving domain.\n",
      "http://arxiv.org/abs/2404.04834v1: [ True]\n",
      "This paper discusses the integration of Large Language Models (LLMs) into autonomous agents to enhance cognitive abilities in addressing complex software engineering challenges through LLM-based Multi-Agent (LMA) systems, emphasizing benefits like collaborative problem-solving and scalability. It envisions the role of LMA systems in future software engineering practices, highlighting potential applications, emerging challenges, and research opportunities to guide future directions.\n",
      "http://arxiv.org/abs/2404.04854v1: [ True]\n",
      "Honeyfiles are security tools that mimic sensitive documents to detect intruders on compromised systems, revealing their presence and intentions. A new approach combining a multitask Transformer and a multi-head autoencoder is proposed to generate realistic document charts for honeyfiles, with experiments showing superior performance compared to large language models like ChatGPT and GPT4.\n",
      "http://arxiv.org/abs/2404.04997v1: [ True]\n",
      "The study introduces SoftPromptComp, a novel framework that combines natural language summarization and soft prompt compression to enhance Large Language Models' (LLMs) efficacy in processing extensive contexts more efficiently and with improved content quality, thereby reducing computational burdens and boosting model performance across various benchmarks. By leveraging synergies between summarization and prompt compression, SoftPromptComp addresses the challenges of managing lengthy contexts and ensuring scalability of LLMs, paving the way for more versatile and pragmatic applications of these models in real-world scenarios.\n",
      "http://arxiv.org/abs/2404.05143v1: [ True]\n",
      "This work explores using Prompt Tuning with prompt embeddings to control language generation with Transformer-based Large Language Models, requiring only a small dataset for training. Through evaluation on four datasets, the method has shown effectiveness in steering language model outputs and mitigating harmful, toxic, and biased text generation.\n",
      "http://arxiv.org/abs/2404.05213v1: [ True]\n",
      "There is a growing interest in using Large Language Models (LLMs) in Human-Computer Interaction (HCI) research, but caution is advised to avoid viewing LLMs as a one-size-fits-all solution. The evaluation of an LLM for identifying logical fallacies showed promising accuracy levels of 0.79 to 0.90, supporting its application while recognizing its limitations.\n",
      "http://arxiv.org/abs/2404.05221v1: [ True]\n",
      "This text discusses the challenges in systematically analyzing diverse reasoning strategies in Large Language Models (LLMs) due to a lack of automated evaluation methods and unified formalism. To address this gap, the paper introduces AutoRace for automated reasoning chain evaluation and LLM Reasoners for standardized implementation of reasoning algorithms, leading to insightful findings on factors influencing reasoning approaches like reward-guidance, search strategies, and world models.\n",
      "http://arxiv.org/abs/2404.05238v1: [ True]\n",
      "The text discusses the use of feature attribution maps for explaining AI decisions and explores the impact of allowing users to edit these maps on human-AI team accuracy, presenting an interactive CHM-Corr++ interface for this purpose. Despite expectations, a user study involving machine learning researchers did not find improved accuracy in bird image classification with the interactive approach, challenging assumptions about the inherent effectiveness of interactive XAI and suggesting the need for further research in the field.\n",
      "http://arxiv.org/abs/2404.05427v1: [ True]\n",
      "Researchers have developed automated techniques using Large Language Models (LLMs) to assist in software development tasks such as issue summarization, bug reproduction, fault localization, and program repair. The proposed AutoCodeRover approach combines LLMs with sophisticated code search capabilities to autonomously improve programs by enhancing understanding of the issue's root cause and retrieving relevant context for modification or patching, showing increased efficacy in resolving real-life Github issues.\n",
      "http://arxiv.org/abs/2404.05442v1: [ True]\n",
      "This paper explores using ChatGPT, a generative AI tool, to develop user personas and adaptive interfaces as an alternative to traditional manual processes, showing promising results in improving the design process efficiency. By leveraging the power of Large Language Models, there is potential to streamline the time, effort, and cost associated with user research for user-centered applications.\n",
      "http://arxiv.org/abs/2404.05449v1: [ True]\n",
      "A framework called Reflection on search Trees (RoT) is introduced to enhance the performance of large language models (LLMs) in reasoning and planning tasks by summarizing guidelines from previous search experiences to prevent repeated mistakes. RoT significantly improves LLM performance with tree-search-based prompting methods like BFS and MCTS, and can also benefit non-tree-search-based methods by providing task-specific knowledge derived from search experiences.\n",
      "http://arxiv.org/abs/2404.05602v1: [ True]\n",
      "This research proposes an AI-powered cyber incident response system for cloud environments, using AI and ML for Network Traffic Classification and Malware Analysis, achieving high accuracy rates of 90% and 96% respectively with the Random Forest model. The study emphasizes the efficiency and scalability of AI/ML systems in cloud environments, utilizing container technology and cloud-based TPUs and GPUs for managing resource demands and ensuring a robust cyber incident response solution.\n",
      "http://arxiv.org/abs/2404.05602v2: [ True]\n",
      "This research proposes an AI-powered cyber incident response system for cloud environments using AI and ML techniques like the Random Forest model, achieving high accuracy rates. The study emphasizes the efficiency and scalability of AI/ML systems hosted in cloud environments, utilizing container technology and cloud-based TPUs and GPUs to manage resource demands.\n",
      "http://arxiv.org/abs/2404.05836v1: [ True]\n",
      "Robotic process automation (RPA) has garnered significant attention as a software technology and has led to diverse research streams. Through a systematic framework utilizing unsupervised machine learning, the study identified 100 distinct study topics related to RPA, with 15 included in the science map created to guide further research in this area.\n",
      "http://arxiv.org/abs/2404.05970v1: [ True]\n",
      "This paper explores retrieval-augmented methods for personalizing large language models, introducing optimization algorithms that improve the delivery of personal documents to enhance personalized generation. Through experimentation on various tasks, the study demonstrates significant enhancements in dataset performance by optimizing retrieval models for personalized generation tasks.\n",
      "http://arxiv.org/abs/2404.06063v1: [ True]\n",
      "Aspect-Based Sentiment Analysis (ABSA) is a complex task in natural language processing, with current efforts focusing on specific sub-tasks. A proposed All in One (AiO) model utilizes Generative Pre-trained Transformers (GPTs) for all ABSA sub-tasks, showing effectiveness in handling such tasks even with limited data through two-stage processing.\n",
      "http://arxiv.org/abs/2404.06082v1: [ True]\n",
      "The study addresses how the context length limitation of large language models affects their use in software development tasks, proposing a method that integrates execution traces into the retrieval-augmented generation (RAG) model for source code queries. Initial experiments suggest that this method shows potential in enhancing the response quality of large language models for software-related inquiries.\n",
      "http://arxiv.org/abs/2404.06162v1: [ True]\n",
      "This paper investigates the abilities of large language models (LLMs) in financial report summarization, finding that Claude 2 outperforms GPT-4 in handling long multimodal inputs. The study identifies a position bias in LLMs, with GPT-3.5 and Command failing to meaningfully summarize financial reports, while Claude 2 and GPT-4 show potential with further analysis on extractiveness and numeric data use.\n",
      "http://arxiv.org/abs/2404.06201v1: [ True]\n",
      "Large Language Models (LLMs) are crucial for improving software engineering tasks by enhancing code understanding, but their collaboration relies heavily on accessing high-quality data, which can be restricted due to commercial and privacy concerns, hindering progress in open-source AI-based software engineering projects. To address this challenge, a governance framework centered on federated learning (FL) is proposed to enable open-source AI models to leverage diverse organizational resources while ensuring data privacy and security, along with guidelines for developers on collaboration aspects such as data requirements, model architecture, updating strategies, and version control.\n",
      "http://arxiv.org/abs/2404.06278v1: [ True]\n",
      "This paper discusses the advantages of using Fast Fourier Transform (FFT) for dimensionality reduction in vector databases to enhance computational efficiency and improve AI model performance across various domains, such as image processing and RAG models. By directly handling embedding vectors post-processing, this FFT-based approach offers promise in optimizing real-time operations, recommendation systems, and addressing data volume challenges in AI research and applications.\n",
      "http://arxiv.org/abs/2404.06311v1: [ True]\n",
      "This paper introduces Data-level Recommendation Explanation (DRE), a transparent framework for black-box recommendation systems that does not require intermediary representations or latent alignment training. By leveraging large language models, DRE provides accurate and user-centric explanations, improving user engagement with recommended items based on user behavior and item reviews.\n",
      "http://arxiv.org/abs/2404.06404v1: [ True]\n",
      "Large Language Models (LLMs) are powerful tools in research, offering benefits like cost-effectiveness and efficiency, but they also pose challenges such as prompt tuning, biases, and subjectivity that need to be addressed. This study explores the potential of LLMs through literature review and experimentation, highlighting successes, limitations, and strategies for mitigating challenges to integrate them into research ethically.\n",
      "http://arxiv.org/abs/2404.06411v1: [ True]\n",
      "Advances in Large Language Models have spurred the development of LLM agents for complex reasoning tasks, emphasizing the importance of benchmarking and evaluation for progress. The AgentQuest framework offers modular benchmarks and new evaluation metrics to track LLM agent progress effectively, highlighting common failure points and enhancing performance through refined architecture, aiming for community collaboration and extension.\n",
      "http://arxiv.org/abs/2404.06733v1: [ True]\n",
      "Explainable AI (XAI) techniques aim to provide interpretable explanations by utilizing sparse linear factors, but current approaches often offer inaccurate global explanations or inconsistent local explanations. To address this, Incremental XAI leverages human cognitive abilities to gradually provide more detailed explanations, improving memorability and faithfulness by presenting Base + Incremental factors for general and atypical instances. Through studies assessing faithfulness, memorability, and understandability, Incremental XAI offers a more user-friendly approach to AI explanations that can be easily understood and remembered by users.\n",
      "http://arxiv.org/abs/2404.06777v1: [ True]\n",
      "Integrating AI and federated learning in smart transportation raises concerns about responsible use, crucial for system stability and sustainability. Research on the responsible application of AI and FL in this area is limited, with a need for more thorough exploration and solutions to challenges in developing and implementing responsible FL.\n",
      "http://arxiv.org/abs/2404.06910v1: [ True]\n",
      "Large language models have limitations in processing long contexts due to their quadratic inference cost, impacting real-world text processing applications like retrieval-augmented generation. A new superposition prompting methodology is proposed to enhance efficiency and accuracy by allowing parallel processing of input documents in pre-trained transformer-based LLMs without fine-tuning, resulting in significant improvements in compute time and accuracy for question-answering tasks.\n",
      "http://arxiv.org/abs/2404.07143v1: [ True]\n",
      "This work presents a method to extend Transformer-based Large Language Models to process infinitely long inputs efficiently using a new attention technique called Infini-attention, which incorporates compressive memory and different attention mechanisms in a single Transformer block. The approach demonstrates effectiveness in tasks like long-context language modeling and book summarization with 1B and 8B LLMs, enabling fast streaming inference with minimal memory parameters.\n",
      "http://arxiv.org/abs/2404.07413v1: [ True]\n",
      "The JetMoE-8B is a cost-effective Large Language Model trained with minimal resources, showcasing impressive performance and outperforming other models, indicating that LLM training can be more affordable than previously believed. JetMoE-8B utilizes an efficient Sparsely-gated Mixture-of-Experts architecture, with sparsely activated layers reducing inference computation by about 70% compared to other models, and it promotes transparency, collaboration, and advancements in accessible and efficient LLM development.\n",
      "http://arxiv.org/abs/2404.07461v1: [ True]\n",
      "A study examines how hallucination is understood in large language models by analyzing 103 research papers and conducting a survey with 171 NLP and AI experts, revealing a lack of consensus on the term and the need for clear definitions and frameworks in the field. The research highlights the importance of defining hallucination in NLP, emphasizing potential challenges and societal impacts, based on insights gathered from practitioners in the field.\n",
      "http://arxiv.org/abs/2404.07471v1: [ True]\n",
      "This paper introduces Structure-aware Fine-tuning (SAT) as a method to improve the absorption of structural knowledge in fine-tuning Code Pre-trained Models (CodePTMs) using a structure loss and multi-task learning, demonstrating its effectiveness through experiments on multiple models and tasks with limited training data. By leveraging attention scores from Transformer layers and shortest path length in abstract syntax trees, SAT enhances the performance of CodePTMs by bridging the gap between learned information and code structure knowledge.\n",
      "http://arxiv.org/abs/2404.07475v1: [ True]\n",
      "The study explores how generative language models can perpetuate biases and harm minoritized individuals through omission, subordination, and stereotyping, even without explicit identity prompts. Findings reveal a prevalence of harmful portrayals and stereotypes in the outputs of popular language models, emphasizing the critical need to address discriminatory impacts and prioritize AI education for diverse consumers.\n",
      "http://arxiv.org/abs/2404.07499v1: [ True]\n",
      "This study explores using large language models to predict if users will find recommended items serendipitously, but the alignment between LLM and human evaluations is not very high. To improve predictions, the study suggests carefully selecting the number of user rating histories provided to LLM prompts.\n",
      "http://arxiv.org/abs/2404.07501v1: [ True]\n",
      "Research in business process modeling explores automated generation of process models from data, such as event logs and natural language texts, aiming to reduce costs and improve efficiency. This study investigates using data augmentation techniques from machine learning to enhance accuracy in extracting business process information from text, showing promising results in improving $F_1$ scores for mention and relation extraction. The findings suggest that data augmentation plays a crucial role in advancing machine learning methods for business process model generation from natural language text, offering insights through visualization and analysis of augmented textual data.\n",
      "http://arxiv.org/abs/2404.07738v1: [ True]\n",
      "A ResearchAgent powered by a language model is proposed to streamline scientific research by automatically generating and refining research ideas, methods, and experiment designs through iterative processes based on existing literature. By connecting information from academic graphs and entity-centric knowledge stores, as well as incorporating peer review feedback, the ResearchAgent demonstrates effectiveness in producing innovative and valid research ideas across various disciplines.\n",
      "http://arxiv.org/abs/2404.07851v1: [ True]\n",
      "This work combines large language models (LLMs) with supervised machine translation (MT) systems by guiding LLMs to automatically post-edit MT with external feedback based on Multidimensional Quality Metric (MQM) annotations. Experiment results on Chinese-English, English-German, and English-Russian show that prompting LLMs to post-edit MT improves translation quality metrics like TER, BLEU, and COMET scores, while fine-tuning the LLMs enhances integration of feedback and improves translation quality further according to both automatic and human evaluation.\n",
      "http://arxiv.org/abs/2404.07917v1: [ True]\n",
      "DesignQA is a benchmark that assesses how well multimodal large language models (MLLMs) can understand and implement engineering requirements using a combination of textual design requirements, CAD images, and engineering drawings from the Formula SAE competition. The benchmark includes visual questions from different sources and evaluates tasks related to rule comprehension, compliance, and extraction, revealing current limitations in MLLMs' ability to accurately interpret complex engineering documentation and apply detailed requirements in designs. This research aims to advance AI-supported engineering design processes and is publicly accessible at https://github.com/anniedoris/design_qa/.\n",
      "http://arxiv.org/abs/2404.07981v1: [ True]\n",
      "This study explores how strategic text sequences (STS) can be used to manipulate large language models (LLMs) to increase a product's visibility as a top recommendation, affecting buyer decisions and competitive advantages. By adding carefully crafted messages to product information pages, both seldom-recommended and second-ranking products can significantly improve their chances of appearing as the top recommendation from LLMs, potentially disrupting fair market competition and revolutionizing content optimization for AI-driven search services.\n",
      "http://arxiv.org/abs/2404.08189v1: [ True]\n",
      "Generative AI often faces the issue of hallucinations, hindering user adoption, but the use of Retrieval Augmented Generation (RAG) can minimize this problem and enhance the quality of workflow outputs. By implementing RAG alongside a well-trained retriever encoder, the system effectively reduces hallucinations, improves generalization in diverse settings, and makes LLM-based deployments more efficient in terms of resource usage.\n",
      "http://arxiv.org/abs/2404.08361v2: [ True]\n",
      "Multi-domain learning is essential for improving feed recommendation systems by accurately capturing user interests across various scenarios. The Automatic Domain Feature Extraction and Personalized Integration (DFEI) framework proposed in the paper addresses the challenges of manually designing domain features and leveraging user behavior data to enhance recommendation accuracy, demonstrating superior performance compared to existing methods across 20 domains.\n",
      "http://arxiv.org/abs/2404.08417v1: [ True]\n",
      "Large language models can now handle complex tasks by recalling information from a pretraining corpus, but concerns arise regarding evolving data needs, such as introducing new data batches or managing user-based data access. AdapterSwap is introduced as a solution to organize knowledge into low-rank adapters, allowing for efficient continual learning and fine-grained control over data access and deletion.\n",
      "http://arxiv.org/abs/2404.08480v1: [ True]\n",
      "Recent advancements in generative AI are reshaping Data Science, and a critical review evaluates ChatGPT's Data Analysis capabilities, highlighting its strengths and limitations. Despite offering researchers and practitioners advanced analytical tools, it is crucial to acknowledge and overcome the current limitations in Data Analysis.\n",
      "http://arxiv.org/abs/2404.08511v1: [ True]\n",
      "This study introduces a novel approach to cross-domain knowledge discovery by deploying specialized multi-AI agents that collaborate to provide comprehensive insights beyond single-domain expertise. Through comparative analysis, the research demonstrates the superior capability of domain-specific multi-AI agents in identifying and bridging knowledge gaps, highlighting the importance of collaborative AI in driving innovation and advancing cross-disciplinary research and applications.\n",
      "http://arxiv.org/abs/2404.08721v1: [ True]\n",
      "Explainable AI research focuses on making AI systems transparent and interpretable, with Counterfactual Explanations (CFEs) providing insights into how machine learning algorithms make decisions by exploring alternative scenarios. This paper highlights the importance of tailoring CFEs to meet diverse user needs and objectives across different applications to enhance collaboration with AI systems.\n",
      "http://arxiv.org/abs/2404.08940v1: [ True]\n",
      "A new approach called Super Retrieval-Augmented Generation (Super RAGs) is integrated into a top-tier Large Language Model (LLM) to improve performance by incorporating external knowledge sources with minimal structural changes, resulting in notable enhancements in accuracy, speed, and user satisfaction. The study showcases the effectiveness of Super RAGs in enhancing LLMs through a fine-tuned instruct model setup and cache tuning fork system, demonstrating significant improvements across various metrics over multiple evaluation epochs, indicating the potential for more advanced and dependable AI systems.\n",
      "http://arxiv.org/abs/2404.09022v1: [ True]\n",
      "This article reviews the increasing use of large models like ChatGPT in various industries and online platforms. It explores advanced fine-tuning methods such as task-adaptive, domain-adaptive, few-shot learning, knowledge distillation, multi-task learning, parameter-efficient, and dynamic fine-tuning for these models.\n",
      "http://arxiv.org/abs/2404.09554v1: [ True]\n",
      "Generative AI (GenAI) has expanded AI capabilities from recognition to generating solutions across various tasks, prompting the need for explainability (XAI) to understand complex outputs. This research discusses the growing importance of XAI in the context of GenAI, outlining key challenges and novel criteria for explanations, offering a taxonomy to categorize existing XAI mechanisms and methods for GenAI.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_preds)):\n",
    "    if new_preds[i] == True:\n",
    "        paper_id = new_ids[i][\"paper_id\"]\n",
    "        summary = new_ids[i][\"concise_summary\"]\n",
    "        print(f\"{paper_id}: {new_preds[i]}\\n{summary}\")\n",
    "        formatted.append({\"id\": paper_id, \"summary\": summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8735822f-444a-423a-a098-4a758e39b206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'http://arxiv.org/abs/2404.04298v1', 'summary': 'The study investigates whether Language Models (LLMs) can enhance their performance by refining previous outputs. Despite introducing a framework to evaluate generative and discriminative abilities, the experimental analysis of various LLMs suggests that they do not consistently excel in discrimination over initial generation, which could impact the advancement of self-improving AI systems.'}, {'id': 'http://arxiv.org/abs/2404.04361v1', 'summary': \"The study examines Large Language Models' (LLMs) effectiveness in predicting entity-specific sentiment from political news articles using zero-shot and few-shot strategies. The research highlights LLMs' superior performance over fine-tuned BERT models in capturing entity-specific sentiment, emphasizing the significance of suitable prompting strategies and model architectures in entity-centric sentiment analysis within the political news domain.\"}, {'id': 'http://arxiv.org/abs/2404.04540v1', 'summary': 'Foundation models (FMs) have transformed various computing domains such as Automated Planning and Scheduling (APS) by aiding in tasks like plan generation, translation, and optimization. This paper emphasizes the importance of developing a comprehensive FM specifically for planning-like (PL) tasks like business processes and workflows to enhance problem-solving capabilities similar to how large language models (LLMs) are benefiting APS.'}, {'id': 'http://arxiv.org/abs/2404.04570v1', 'summary': 'This text discusses the impact of large language models on AI system interaction patterns and highlights the lack of focus on human interaction with LLM in current literature reviews. The authors conducted a detailed review and mapping of 110 relevant publications, offering insights into human-LLM interaction patterns and identifying key challenges in this area.'}, {'id': 'http://arxiv.org/abs/2404.04750v2', 'summary': 'The advancements in artificial intelligence present both opportunities and challenges for society, with the potential to significantly impact humanity akin to the industrial revolution. The One Hundred Year Study on AI, founded by multidisciplinary experts, emphasizes the importance of understanding AI models, addressing societal impacts, and fostering collaboration among stakeholders to guide the development of AI responsibly for human benefit.'}, {'id': 'http://arxiv.org/abs/2404.04821v1', 'summary': 'AI is reshaping Software Engineering with a focus on Automated Software Evolution for intelligent applications, presenting complexity from data heterogeneity and changing contexts. A proposed conceptual framework emphasizes multimodality learning and offers a Selective Sequential Scope Model (3S) for categorizing research across SE phases, serving as a practical guide for practitioners venturing into this evolving domain.'}, {'id': 'http://arxiv.org/abs/2404.04834v1', 'summary': 'This paper discusses the integration of Large Language Models (LLMs) into autonomous agents to enhance cognitive abilities in addressing complex software engineering challenges through LLM-based Multi-Agent (LMA) systems, emphasizing benefits like collaborative problem-solving and scalability. It envisions the role of LMA systems in future software engineering practices, highlighting potential applications, emerging challenges, and research opportunities to guide future directions.'}, {'id': 'http://arxiv.org/abs/2404.04854v1', 'summary': 'Honeyfiles are security tools that mimic sensitive documents to detect intruders on compromised systems, revealing their presence and intentions. A new approach combining a multitask Transformer and a multi-head autoencoder is proposed to generate realistic document charts for honeyfiles, with experiments showing superior performance compared to large language models like ChatGPT and GPT4.'}, {'id': 'http://arxiv.org/abs/2404.04997v1', 'summary': \"The study introduces SoftPromptComp, a novel framework that combines natural language summarization and soft prompt compression to enhance Large Language Models' (LLMs) efficacy in processing extensive contexts more efficiently and with improved content quality, thereby reducing computational burdens and boosting model performance across various benchmarks. By leveraging synergies between summarization and prompt compression, SoftPromptComp addresses the challenges of managing lengthy contexts and ensuring scalability of LLMs, paving the way for more versatile and pragmatic applications of these models in real-world scenarios.\"}, {'id': 'http://arxiv.org/abs/2404.05143v1', 'summary': 'This work explores using Prompt Tuning with prompt embeddings to control language generation with Transformer-based Large Language Models, requiring only a small dataset for training. Through evaluation on four datasets, the method has shown effectiveness in steering language model outputs and mitigating harmful, toxic, and biased text generation.'}, {'id': 'http://arxiv.org/abs/2404.05213v1', 'summary': 'There is a growing interest in using Large Language Models (LLMs) in Human-Computer Interaction (HCI) research, but caution is advised to avoid viewing LLMs as a one-size-fits-all solution. The evaluation of an LLM for identifying logical fallacies showed promising accuracy levels of 0.79 to 0.90, supporting its application while recognizing its limitations.'}, {'id': 'http://arxiv.org/abs/2404.05221v1', 'summary': 'This text discusses the challenges in systematically analyzing diverse reasoning strategies in Large Language Models (LLMs) due to a lack of automated evaluation methods and unified formalism. To address this gap, the paper introduces AutoRace for automated reasoning chain evaluation and LLM Reasoners for standardized implementation of reasoning algorithms, leading to insightful findings on factors influencing reasoning approaches like reward-guidance, search strategies, and world models.'}, {'id': 'http://arxiv.org/abs/2404.05238v1', 'summary': 'The text discusses the use of feature attribution maps for explaining AI decisions and explores the impact of allowing users to edit these maps on human-AI team accuracy, presenting an interactive CHM-Corr++ interface for this purpose. Despite expectations, a user study involving machine learning researchers did not find improved accuracy in bird image classification with the interactive approach, challenging assumptions about the inherent effectiveness of interactive XAI and suggesting the need for further research in the field.'}, {'id': 'http://arxiv.org/abs/2404.05427v1', 'summary': \"Researchers have developed automated techniques using Large Language Models (LLMs) to assist in software development tasks such as issue summarization, bug reproduction, fault localization, and program repair. The proposed AutoCodeRover approach combines LLMs with sophisticated code search capabilities to autonomously improve programs by enhancing understanding of the issue's root cause and retrieving relevant context for modification or patching, showing increased efficacy in resolving real-life Github issues.\"}, {'id': 'http://arxiv.org/abs/2404.05442v1', 'summary': 'This paper explores using ChatGPT, a generative AI tool, to develop user personas and adaptive interfaces as an alternative to traditional manual processes, showing promising results in improving the design process efficiency. By leveraging the power of Large Language Models, there is potential to streamline the time, effort, and cost associated with user research for user-centered applications.'}, {'id': 'http://arxiv.org/abs/2404.05449v1', 'summary': 'A framework called Reflection on search Trees (RoT) is introduced to enhance the performance of large language models (LLMs) in reasoning and planning tasks by summarizing guidelines from previous search experiences to prevent repeated mistakes. RoT significantly improves LLM performance with tree-search-based prompting methods like BFS and MCTS, and can also benefit non-tree-search-based methods by providing task-specific knowledge derived from search experiences.'}, {'id': 'http://arxiv.org/abs/2404.05602v1', 'summary': 'This research proposes an AI-powered cyber incident response system for cloud environments, using AI and ML for Network Traffic Classification and Malware Analysis, achieving high accuracy rates of 90% and 96% respectively with the Random Forest model. The study emphasizes the efficiency and scalability of AI/ML systems in cloud environments, utilizing container technology and cloud-based TPUs and GPUs for managing resource demands and ensuring a robust cyber incident response solution.'}, {'id': 'http://arxiv.org/abs/2404.05602v2', 'summary': 'This research proposes an AI-powered cyber incident response system for cloud environments using AI and ML techniques like the Random Forest model, achieving high accuracy rates. The study emphasizes the efficiency and scalability of AI/ML systems hosted in cloud environments, utilizing container technology and cloud-based TPUs and GPUs to manage resource demands.'}, {'id': 'http://arxiv.org/abs/2404.05836v1', 'summary': 'Robotic process automation (RPA) has garnered significant attention as a software technology and has led to diverse research streams. Through a systematic framework utilizing unsupervised machine learning, the study identified 100 distinct study topics related to RPA, with 15 included in the science map created to guide further research in this area.'}, {'id': 'http://arxiv.org/abs/2404.05970v1', 'summary': 'This paper explores retrieval-augmented methods for personalizing large language models, introducing optimization algorithms that improve the delivery of personal documents to enhance personalized generation. Through experimentation on various tasks, the study demonstrates significant enhancements in dataset performance by optimizing retrieval models for personalized generation tasks.'}, {'id': 'http://arxiv.org/abs/2404.06063v1', 'summary': 'Aspect-Based Sentiment Analysis (ABSA) is a complex task in natural language processing, with current efforts focusing on specific sub-tasks. A proposed All in One (AiO) model utilizes Generative Pre-trained Transformers (GPTs) for all ABSA sub-tasks, showing effectiveness in handling such tasks even with limited data through two-stage processing.'}, {'id': 'http://arxiv.org/abs/2404.06082v1', 'summary': 'The study addresses how the context length limitation of large language models affects their use in software development tasks, proposing a method that integrates execution traces into the retrieval-augmented generation (RAG) model for source code queries. Initial experiments suggest that this method shows potential in enhancing the response quality of large language models for software-related inquiries.'}, {'id': 'http://arxiv.org/abs/2404.06162v1', 'summary': 'This paper investigates the abilities of large language models (LLMs) in financial report summarization, finding that Claude 2 outperforms GPT-4 in handling long multimodal inputs. The study identifies a position bias in LLMs, with GPT-3.5 and Command failing to meaningfully summarize financial reports, while Claude 2 and GPT-4 show potential with further analysis on extractiveness and numeric data use.'}, {'id': 'http://arxiv.org/abs/2404.06201v1', 'summary': 'Large Language Models (LLMs) are crucial for improving software engineering tasks by enhancing code understanding, but their collaboration relies heavily on accessing high-quality data, which can be restricted due to commercial and privacy concerns, hindering progress in open-source AI-based software engineering projects. To address this challenge, a governance framework centered on federated learning (FL) is proposed to enable open-source AI models to leverage diverse organizational resources while ensuring data privacy and security, along with guidelines for developers on collaboration aspects such as data requirements, model architecture, updating strategies, and version control.'}, {'id': 'http://arxiv.org/abs/2404.06278v1', 'summary': 'This paper discusses the advantages of using Fast Fourier Transform (FFT) for dimensionality reduction in vector databases to enhance computational efficiency and improve AI model performance across various domains, such as image processing and RAG models. By directly handling embedding vectors post-processing, this FFT-based approach offers promise in optimizing real-time operations, recommendation systems, and addressing data volume challenges in AI research and applications.'}, {'id': 'http://arxiv.org/abs/2404.06311v1', 'summary': 'This paper introduces Data-level Recommendation Explanation (DRE), a transparent framework for black-box recommendation systems that does not require intermediary representations or latent alignment training. By leveraging large language models, DRE provides accurate and user-centric explanations, improving user engagement with recommended items based on user behavior and item reviews.'}, {'id': 'http://arxiv.org/abs/2404.06404v1', 'summary': 'Large Language Models (LLMs) are powerful tools in research, offering benefits like cost-effectiveness and efficiency, but they also pose challenges such as prompt tuning, biases, and subjectivity that need to be addressed. This study explores the potential of LLMs through literature review and experimentation, highlighting successes, limitations, and strategies for mitigating challenges to integrate them into research ethically.'}, {'id': 'http://arxiv.org/abs/2404.06411v1', 'summary': 'Advances in Large Language Models have spurred the development of LLM agents for complex reasoning tasks, emphasizing the importance of benchmarking and evaluation for progress. The AgentQuest framework offers modular benchmarks and new evaluation metrics to track LLM agent progress effectively, highlighting common failure points and enhancing performance through refined architecture, aiming for community collaboration and extension.'}, {'id': 'http://arxiv.org/abs/2404.06733v1', 'summary': 'Explainable AI (XAI) techniques aim to provide interpretable explanations by utilizing sparse linear factors, but current approaches often offer inaccurate global explanations or inconsistent local explanations. To address this, Incremental XAI leverages human cognitive abilities to gradually provide more detailed explanations, improving memorability and faithfulness by presenting Base + Incremental factors for general and atypical instances. Through studies assessing faithfulness, memorability, and understandability, Incremental XAI offers a more user-friendly approach to AI explanations that can be easily understood and remembered by users.'}, {'id': 'http://arxiv.org/abs/2404.06777v1', 'summary': 'Integrating AI and federated learning in smart transportation raises concerns about responsible use, crucial for system stability and sustainability. Research on the responsible application of AI and FL in this area is limited, with a need for more thorough exploration and solutions to challenges in developing and implementing responsible FL.'}, {'id': 'http://arxiv.org/abs/2404.06910v1', 'summary': 'Large language models have limitations in processing long contexts due to their quadratic inference cost, impacting real-world text processing applications like retrieval-augmented generation. A new superposition prompting methodology is proposed to enhance efficiency and accuracy by allowing parallel processing of input documents in pre-trained transformer-based LLMs without fine-tuning, resulting in significant improvements in compute time and accuracy for question-answering tasks.'}, {'id': 'http://arxiv.org/abs/2404.07143v1', 'summary': 'This work presents a method to extend Transformer-based Large Language Models to process infinitely long inputs efficiently using a new attention technique called Infini-attention, which incorporates compressive memory and different attention mechanisms in a single Transformer block. The approach demonstrates effectiveness in tasks like long-context language modeling and book summarization with 1B and 8B LLMs, enabling fast streaming inference with minimal memory parameters.'}, {'id': 'http://arxiv.org/abs/2404.07413v1', 'summary': 'The JetMoE-8B is a cost-effective Large Language Model trained with minimal resources, showcasing impressive performance and outperforming other models, indicating that LLM training can be more affordable than previously believed. JetMoE-8B utilizes an efficient Sparsely-gated Mixture-of-Experts architecture, with sparsely activated layers reducing inference computation by about 70% compared to other models, and it promotes transparency, collaboration, and advancements in accessible and efficient LLM development.'}, {'id': 'http://arxiv.org/abs/2404.07461v1', 'summary': 'A study examines how hallucination is understood in large language models by analyzing 103 research papers and conducting a survey with 171 NLP and AI experts, revealing a lack of consensus on the term and the need for clear definitions and frameworks in the field. The research highlights the importance of defining hallucination in NLP, emphasizing potential challenges and societal impacts, based on insights gathered from practitioners in the field.'}, {'id': 'http://arxiv.org/abs/2404.07471v1', 'summary': 'This paper introduces Structure-aware Fine-tuning (SAT) as a method to improve the absorption of structural knowledge in fine-tuning Code Pre-trained Models (CodePTMs) using a structure loss and multi-task learning, demonstrating its effectiveness through experiments on multiple models and tasks with limited training data. By leveraging attention scores from Transformer layers and shortest path length in abstract syntax trees, SAT enhances the performance of CodePTMs by bridging the gap between learned information and code structure knowledge.'}, {'id': 'http://arxiv.org/abs/2404.07475v1', 'summary': 'The study explores how generative language models can perpetuate biases and harm minoritized individuals through omission, subordination, and stereotyping, even without explicit identity prompts. Findings reveal a prevalence of harmful portrayals and stereotypes in the outputs of popular language models, emphasizing the critical need to address discriminatory impacts and prioritize AI education for diverse consumers.'}, {'id': 'http://arxiv.org/abs/2404.07499v1', 'summary': 'This study explores using large language models to predict if users will find recommended items serendipitously, but the alignment between LLM and human evaluations is not very high. To improve predictions, the study suggests carefully selecting the number of user rating histories provided to LLM prompts.'}, {'id': 'http://arxiv.org/abs/2404.07501v1', 'summary': 'Research in business process modeling explores automated generation of process models from data, such as event logs and natural language texts, aiming to reduce costs and improve efficiency. This study investigates using data augmentation techniques from machine learning to enhance accuracy in extracting business process information from text, showing promising results in improving $F_1$ scores for mention and relation extraction. The findings suggest that data augmentation plays a crucial role in advancing machine learning methods for business process model generation from natural language text, offering insights through visualization and analysis of augmented textual data.'}, {'id': 'http://arxiv.org/abs/2404.07738v1', 'summary': 'A ResearchAgent powered by a language model is proposed to streamline scientific research by automatically generating and refining research ideas, methods, and experiment designs through iterative processes based on existing literature. By connecting information from academic graphs and entity-centric knowledge stores, as well as incorporating peer review feedback, the ResearchAgent demonstrates effectiveness in producing innovative and valid research ideas across various disciplines.'}, {'id': 'http://arxiv.org/abs/2404.07851v1', 'summary': 'This work combines large language models (LLMs) with supervised machine translation (MT) systems by guiding LLMs to automatically post-edit MT with external feedback based on Multidimensional Quality Metric (MQM) annotations. Experiment results on Chinese-English, English-German, and English-Russian show that prompting LLMs to post-edit MT improves translation quality metrics like TER, BLEU, and COMET scores, while fine-tuning the LLMs enhances integration of feedback and improves translation quality further according to both automatic and human evaluation.'}, {'id': 'http://arxiv.org/abs/2404.07917v1', 'summary': \"DesignQA is a benchmark that assesses how well multimodal large language models (MLLMs) can understand and implement engineering requirements using a combination of textual design requirements, CAD images, and engineering drawings from the Formula SAE competition. The benchmark includes visual questions from different sources and evaluates tasks related to rule comprehension, compliance, and extraction, revealing current limitations in MLLMs' ability to accurately interpret complex engineering documentation and apply detailed requirements in designs. This research aims to advance AI-supported engineering design processes and is publicly accessible at https://github.com/anniedoris/design_qa/.\"}, {'id': 'http://arxiv.org/abs/2404.07981v1', 'summary': \"This study explores how strategic text sequences (STS) can be used to manipulate large language models (LLMs) to increase a product's visibility as a top recommendation, affecting buyer decisions and competitive advantages. By adding carefully crafted messages to product information pages, both seldom-recommended and second-ranking products can significantly improve their chances of appearing as the top recommendation from LLMs, potentially disrupting fair market competition and revolutionizing content optimization for AI-driven search services.\"}, {'id': 'http://arxiv.org/abs/2404.08189v1', 'summary': 'Generative AI often faces the issue of hallucinations, hindering user adoption, but the use of Retrieval Augmented Generation (RAG) can minimize this problem and enhance the quality of workflow outputs. By implementing RAG alongside a well-trained retriever encoder, the system effectively reduces hallucinations, improves generalization in diverse settings, and makes LLM-based deployments more efficient in terms of resource usage.'}, {'id': 'http://arxiv.org/abs/2404.08361v2', 'summary': 'Multi-domain learning is essential for improving feed recommendation systems by accurately capturing user interests across various scenarios. The Automatic Domain Feature Extraction and Personalized Integration (DFEI) framework proposed in the paper addresses the challenges of manually designing domain features and leveraging user behavior data to enhance recommendation accuracy, demonstrating superior performance compared to existing methods across 20 domains.'}, {'id': 'http://arxiv.org/abs/2404.08417v1', 'summary': 'Large language models can now handle complex tasks by recalling information from a pretraining corpus, but concerns arise regarding evolving data needs, such as introducing new data batches or managing user-based data access. AdapterSwap is introduced as a solution to organize knowledge into low-rank adapters, allowing for efficient continual learning and fine-grained control over data access and deletion.'}, {'id': 'http://arxiv.org/abs/2404.08480v1', 'summary': \"Recent advancements in generative AI are reshaping Data Science, and a critical review evaluates ChatGPT's Data Analysis capabilities, highlighting its strengths and limitations. Despite offering researchers and practitioners advanced analytical tools, it is crucial to acknowledge and overcome the current limitations in Data Analysis.\"}, {'id': 'http://arxiv.org/abs/2404.08511v1', 'summary': 'This study introduces a novel approach to cross-domain knowledge discovery by deploying specialized multi-AI agents that collaborate to provide comprehensive insights beyond single-domain expertise. Through comparative analysis, the research demonstrates the superior capability of domain-specific multi-AI agents in identifying and bridging knowledge gaps, highlighting the importance of collaborative AI in driving innovation and advancing cross-disciplinary research and applications.'}, {'id': 'http://arxiv.org/abs/2404.08721v1', 'summary': 'Explainable AI research focuses on making AI systems transparent and interpretable, with Counterfactual Explanations (CFEs) providing insights into how machine learning algorithms make decisions by exploring alternative scenarios. This paper highlights the importance of tailoring CFEs to meet diverse user needs and objectives across different applications to enhance collaboration with AI systems.'}, {'id': 'http://arxiv.org/abs/2404.08940v1', 'summary': 'A new approach called Super Retrieval-Augmented Generation (Super RAGs) is integrated into a top-tier Large Language Model (LLM) to improve performance by incorporating external knowledge sources with minimal structural changes, resulting in notable enhancements in accuracy, speed, and user satisfaction. The study showcases the effectiveness of Super RAGs in enhancing LLMs through a fine-tuned instruct model setup and cache tuning fork system, demonstrating significant improvements across various metrics over multiple evaluation epochs, indicating the potential for more advanced and dependable AI systems.'}, {'id': 'http://arxiv.org/abs/2404.09022v1', 'summary': 'This article reviews the increasing use of large models like ChatGPT in various industries and online platforms. It explores advanced fine-tuning methods such as task-adaptive, domain-adaptive, few-shot learning, knowledge distillation, multi-task learning, parameter-efficient, and dynamic fine-tuning for these models.'}, {'id': 'http://arxiv.org/abs/2404.09554v1', 'summary': 'Generative AI (GenAI) has expanded AI capabilities from recognition to generating solutions across various tasks, prompting the need for explainability (XAI) to understand complex outputs. This research discusses the growing importance of XAI in the context of GenAI, outlining key challenges and novel criteria for explanations, offering a taxonomy to categorize existing XAI mechanisms and methods for GenAI.'}]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(new_preds)):\n",
    "#     if new_preds[i] == True:\n",
    "#         print(f'{new_ids[i][\"paper_id\"]}')\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4835ea91-e2bd-485a-ae74-cf31c3fe11ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/abs/2404.04298v1: SELF-[IN]CORRECT: LLMs Struggle with Refining Self-Generated Responses\n",
      "http://arxiv.org/abs/2404.04361v1: Deciphering Political Entity Sentiment in News with Large Language\n",
      "  Models: Zero-Shot and Few-Shot Strategies\n",
      "http://arxiv.org/abs/2404.04540v1: The Case for Developing a Foundation Model for Planning-like Tasks from\n",
      "  Scratch\n",
      "http://arxiv.org/abs/2404.04570v1: A Map of Exploring Human Interaction patterns with LLM: Insights into\n",
      "  Collaboration and Creativity\n",
      "http://arxiv.org/abs/2404.04750v2: Now, Later, and Lasting: Ten Priorities for AI Research, Policy, and\n",
      "  Practice\n",
      "http://arxiv.org/abs/2404.04821v1: A Data-to-Product Multimodal Conceptual Framework to Achieve Automated\n",
      "  Software Evolution for Context-rich Intelligent Applications\n",
      "http://arxiv.org/abs/2404.04834v1: LLM-Based Multi-Agent Systems for Software Engineering: Vision and the\n",
      "  Road Ahead\n",
      "http://arxiv.org/abs/2404.04854v1: Contextual Chart Generation for Cyber Deception\n",
      "http://arxiv.org/abs/2404.04997v1: Adapting LLMs for Efficient Context Processing through Soft Prompt\n",
      "  Compression\n",
      "http://arxiv.org/abs/2404.05143v1: Plug and Play with Prompts: A Prompt Tuning Approach for Controlling\n",
      "  Text Generation\n",
      "http://arxiv.org/abs/2404.05213v1: Evaluation of an LLM in Identifying Logical Fallacies: A Call for Rigor\n",
      "  When Adopting LLMs in HCI Research\n",
      "http://arxiv.org/abs/2404.05221v1: LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step\n",
      "  Reasoning with Large Language Models\n",
      "http://arxiv.org/abs/2404.05238v1: Allowing humans to interactively guide machines where to look does not\n",
      "  always improve a human-AI team's classification accuracy\n",
      "http://arxiv.org/abs/2404.05427v1: AutoCodeRover: Autonomous Program Improvement\n",
      "http://arxiv.org/abs/2404.05442v1: Unlocking Adaptive User Experience with Generative AI\n",
      "http://arxiv.org/abs/2404.05449v1: RoT: Enhancing Large Language Models with Reflection on Search Trees\n",
      "http://arxiv.org/abs/2404.05602v1: AI-Enabled System for Efficient and Effective Cyber Incident Detection\n",
      "  and Response in Cloud Environments\n",
      "http://arxiv.org/abs/2404.05602v2: AI-Enabled System for Efficient and Effective Cyber Incident Detection\n",
      "  and Response in Cloud Environments\n",
      "http://arxiv.org/abs/2404.05836v1: Unveiling Latent Topics in Robotic Process Automation -- an Approach\n",
      "  based on Latent Dirichlet Allocation Smart Review\n",
      "http://arxiv.org/abs/2404.05970v1: Optimization Methods for Personalizing Large Language Models through\n",
      "  Retrieval Augmentation\n",
      "http://arxiv.org/abs/2404.06063v1: All in One: An Empirical Study of GPT for Few-Shot Aspect-Based\n",
      "  Sentiment Anlaysis\n",
      "http://arxiv.org/abs/2404.06082v1: A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs\n",
      "http://arxiv.org/abs/2404.06162v1: Characterizing Multimodal Long-form Summarization: A Case Study on\n",
      "  Financial Reports\n",
      "http://arxiv.org/abs/2404.06201v1: Open-Source AI-based SE Tools: Opportunities and Challenges of\n",
      "  Collaborative Software Learning\n",
      "http://arxiv.org/abs/2404.06278v1: Dimensionality Reduction in Sentence Transformer Vector Databases with\n",
      "  Fast Fourier Transform\n",
      "http://arxiv.org/abs/2404.06311v1: DRE: Generating Recommendation Explanations by Aligning Large Language\n",
      "  Models at Data-level\n",
      "http://arxiv.org/abs/2404.06404v1: Apprentices to Research Assistants: Advancing Research with Large\n",
      "  Language Models\n",
      "http://arxiv.org/abs/2404.06411v1: AgentQuest: A Modular Benchmark Framework to Measure Progress and\n",
      "  Improve LLM Agents\n",
      "http://arxiv.org/abs/2404.06733v1: Incremental XAI: Memorable Understanding of AI with Incremental\n",
      "  Explanations\n",
      "http://arxiv.org/abs/2404.06777v1: Responsible Federated Learning in Smart Transportation: Outlooks and\n",
      "  Challenges\n",
      "http://arxiv.org/abs/2404.06910v1: Superposition Prompting: Improving and Accelerating Retrieval-Augmented\n",
      "  Generation\n",
      "http://arxiv.org/abs/2404.07143v1: Leave No Context Behind: Efficient Infinite Context Transformers with\n",
      "  Infini-attention\n",
      "http://arxiv.org/abs/2404.07413v1: JetMoE: Reaching Llama2 Performance with 0.1M Dollars\n",
      "http://arxiv.org/abs/2404.07461v1: \"Confidently Nonsensical?'': A Critical Survey on the Perspectives and\n",
      "  Challenges of 'Hallucinations' in NLP\n",
      "http://arxiv.org/abs/2404.07471v1: Structure-aware Fine-tuning for Code Pre-trained Models\n",
      "http://arxiv.org/abs/2404.07475v1: Laissez-Faire Harms: Algorithmic Biases in Generative Language Models\n",
      "http://arxiv.org/abs/2404.07499v1: Can Large Language Models Assess Serendipity in Recommender Systems?\n",
      "http://arxiv.org/abs/2404.07501v1: Leveraging Data Augmentation for Process Information Extraction\n",
      "http://arxiv.org/abs/2404.07738v1: ResearchAgent: Iterative Research Idea Generation over Scientific\n",
      "  Literature with Large Language Models\n",
      "http://arxiv.org/abs/2404.07851v1: Guiding Large Language Models to Post-Edit Machine Translation with\n",
      "  Error Annotations\n",
      "http://arxiv.org/abs/2404.07917v1: DesignQA: A Multimodal Benchmark for Evaluating Large Language Models'\n",
      "  Understanding of Engineering Documentation\n",
      "http://arxiv.org/abs/2404.07981v1: Manipulating Large Language Models to Increase Product Visibility\n",
      "http://arxiv.org/abs/2404.08189v1: Reducing hallucination in structured outputs via Retrieval-Augmented\n",
      "  Generation\n",
      "http://arxiv.org/abs/2404.08361v2: Large-Scale Multi-Domain Recommendation: an Automatic Domain Feature\n",
      "  Extraction and Personalized Integration Framework\n",
      "http://arxiv.org/abs/2404.08417v1: AdapterSwap: Continuous Training of LLMs with Data Removal and\n",
      "  Access-Control Guarantees\n",
      "http://arxiv.org/abs/2404.08480v1: Decoding AI: The inside story of data analysis in ChatGPT\n",
      "http://arxiv.org/abs/2404.08511v1: Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery\n",
      "http://arxiv.org/abs/2404.08721v1: Beyond One-Size-Fits-All: Adapting Counterfactual Explanations to User\n",
      "  Objectives\n",
      "http://arxiv.org/abs/2404.08940v1: Introducing Super RAGs in Mistral 8x7B-v1\n",
      "http://arxiv.org/abs/2404.09022v1: Navigating the Landscape of Large Language Models: A Comprehensive\n",
      "  Review and Analysis of Paradigms and Fine-Tuning Strategies\n",
      "http://arxiv.org/abs/2404.09554v1: Explainable Generative AI (GenXAI): A Survey, Conceptualization, and\n",
      "  Research Agenda\n"
     ]
    }
   ],
   "source": [
    "# Retrieve article titles\n",
    "\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.insert(0, \"/home/woojay/P/ML/arxiver\")\n",
    "\n",
    "from arxiver.database import create_connection\n",
    "\n",
    "conn = create_connection(\"../data/arxiv_papers.db\")\n",
    "\n",
    "if conn is not None:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    for i in range(len(new_preds)):\n",
    "        if new_preds[i] == True:\n",
    "            # Fetch the specific entry\n",
    "            cursor.execute(\n",
    "                \"SELECT paper_id, title, summary, concise_summary FROM papers WHERE paper_id = ?\",\n",
    "                (new_ids[i][\"paper_id\"],),\n",
    "            )\n",
    "            entry = cursor.fetchone()\n",
    "\n",
    "            if not entry:\n",
    "                conn.close()\n",
    "                raise HTTPException(status_code=404, detail=\"Paper not found\")\n",
    "\n",
    "            paper_id, title, summary, concise_summary = entry\n",
    "\n",
    "            print(f\"{paper_id}: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110be7f-f5d9-48b9-abdd-af959e8dfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask openAI to pick the best articles:\n",
    "\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def choose_summaries(summaries, k):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert summarizer capable of distilling complex information into its essence and a skilled evaluator of cutting edge ideas. Your choices should be based on the most interesting, novel, and cutting edge ideas.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"From the following article summaries, pick the {k} most interesting, novel, and cutting edge ideas and return a json list with 'id' and 'summary' for each. The id should contain the article id. You may also include a 'reason' for each choice.: {summaries}\",\n",
    "                },\n",
    "            ],\n",
    "            max_tokens=4096,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        print(response.choices[0].message.content)\n",
    "        response_content = (\n",
    "            response.choices[0]\n",
    "            .message.content.strip(\"`\")\n",
    "            .strip()\n",
    "            .removeprefix(\"json\\n\")\n",
    "        )\n",
    "\n",
    "        # Debugging\n",
    "        # print(\"Raw response content:\", response_content)\n",
    "\n",
    "        if response_content:\n",
    "            parsed_response = json.loads(response_content)\n",
    "            return parsed_response\n",
    "        else:\n",
    "            print(\"Response content is empty.\")\n",
    "            return []\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON:\", e)\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4726e1-d9b5-4f7f-84b1-3b72aad43544",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = choose_summaries(formatted, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe38810-0cfe-4e4d-8a01-8acf67d95553",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67d15d-c069-4f35-8448-c60dff599d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "new_model = Sequential(\n",
    "    [\n",
    "        Dense(\n",
    "            320,\n",
    "            activation=\"relu\",\n",
    "            input_shape=(X_train.shape[1],),\n",
    "            kernel_regularizer=l2(0.001),\n",
    "        ),\n",
    "        Dropout(0.0),\n",
    "        BatchNormalization(),\n",
    "        Dense(224, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b976dd0-7b4d-4891-bac7-d8cdc925cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa1df4-69c8-439f-b489-ee0427e0a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predicted articles\n",
    "\n",
    "new_x = []\n",
    "formatted = []\n",
    "for id in new_ids:\n",
    "    new_x.append(get_embedding(id[\"paper_id\"]))\n",
    "\n",
    "new_preds = model.predict(new_x) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711747c-8c62-492c-b450-14e4dd6f1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_preds)):\n",
    "    if new_preds[i] == True:\n",
    "        paper_id = new_ids[i][\"paper_id\"]\n",
    "        summary = new_ids[i][\"concise_summary\"]\n",
    "        print(f\"{paper_id}: {new_preds[i]}\\n{summary}\")\n",
    "        formatted.append({\"id\": paper_id, \"summary\": summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e31e9-9ae4-404a-b5ae-8ada5fecc091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
